{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c60aa41-76f6-4859-ae01-c53a1aee8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#presuming localCPU test runs and all the bits there are installed.\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from distributed import Client, LocalCluster\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# https://docs.mlerp.cloud.edu.au/tutorials/3_dask_pytorch.html\n",
    "\n",
    "\n",
    "DATASET = [\"Hello, my name is\", \n",
    "           \"You killed my father\",\n",
    "           \"My favourite colours are:\",\n",
    "           \"What is the airspeed of an unladen\"]\n",
    "\n",
    "batch_size = len(DATASET)\n",
    "\n",
    "# https://jobqueue.dask.org/en/latest/debug.html\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd752e75-435a-444e-89f5-f92f54d35414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader = torch.utils.data.DataLoader(DATASET, batch_size=batch_size, shuffle=True, num_workers=1, multiprocessing_context=mp.get_context(\"fork\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2458c0b-cce3-46b5-82a1-d110f11d72b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f875b77e510>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c97d257-d70c-4ccf-8137-04b25de01b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You killed my father', 'My favourite colours are:', 'Hello, my name is', 'What is the airspeed of an unladen']\n"
     ]
    }
   ],
   "source": [
    "for line in dataloader:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f455670-8f51-48c1-ae95-4c224b0985d8",
   "metadata": {},
   "source": [
    "# Here is the `generate` function\n",
    "\n",
    "This function is the thing that runs in the external `cheetah` nodes and is the thing that uses the llm model to compute against the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48af7b5c-dbc5-4ccc-873d-93a580d1360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate(loader, model_id=\"mistralai/Mistral-7B-v0.1\", output=[]): #mistralai/Mixtral-8x7B-v0.1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side=\"left\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "    \n",
    "\n",
    "    for line in loader:\n",
    "        print(\"working on\", line)\n",
    "        # text = \"Hello my name is\"\n",
    "        inputs = tokenizer(line, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "        output.append({\"prompt\":line,\"output\":tokenizer.decode(outputs[0], skip_special_tokens=True)})\n",
    "        print(output)\n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4556f92-436c-420a-a08c-0364ae8ee633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Using selector: EpollSelector\n",
      "DEBUG:Starting worker: SLURMCluster-0\n",
      "DEBUG:writing job script: \n",
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e ./logs/dask-worker-%J.err\n",
      "#SBATCH -o ./logs/dask-worker-%J.out\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --mem=120G\n",
      "#SBATCH -t 00:30:00\n",
      "#SBATCH --gres=gpu:40gb:1\n",
      "\n",
      "/apps/mambaforge/envs/detectron-sam/bin/python -m distributed.cli.dask_worker tcp://192.168.0.11:36209 --nthreads 8 --memory-limit 119.21GiB --name SLURMCluster-0 --no-nanny --death-timeout 60\n",
      "\n",
      "DEBUG:Executing the following command to command line\n",
      "sbatch /tmp/tmpawa1_ytz.sh\n",
      "DEBUG:Starting job: 2537\n"
     ]
    }
   ],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, progress\n",
    "\n",
    "try:\n",
    "    # cluster = LocalCluster(processes=False)\n",
    "    cluster = SLURMCluster(\n",
    "        memory=\"128g\", processes=1, cores=8, job_extra_directives=[\"--gres=gpu:40gb:1\",], nanny=False,\n",
    "        # queue=\"lion\", # check with $ sacctmgr list clusters\n",
    "        # worker_extra_args=[\"-e slurm-%j.err\", \"-o slurm-%j.out\"], # not needed with log_directory\n",
    "        log_directory=\"./logs\", #no trailing slash\n",
    "        \n",
    "    )\n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "    # dataloader_future = client.scatter(dataloader)\n",
    "    # future = client.submit(generate, dataloader_future)\n",
    "    futuremap = client.submit(generate, DATASET)\n",
    "except:\n",
    "    client.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0d52460-22e7-44d2-9b2d-14c16ef092fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTITIO            NAME    STATE       TIME    TIME_LEFT CPUS MIN_MEM NODELIST(REASON) QOS\n",
      " BigCats     dask-worker  RUNNING       0:03        29:57    8    120G mlerp-monash-node03 cheetah\n",
      " BigCats     Jupyter Lab  RUNNING      12:56        47:04    8     64G mlerp-monash-node00 lion\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852418a9d2784e7ea9b2e064c13f4357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!squeue --me --format \"%.8P %.15j %.8T %.10M %.12L %.4C %.7m %R %q\"\n",
    "progress(futuremap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b900b04-b87b-49ec-876c-e923c9bc50cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Hello, my name is', 'output': 'Hello, my name is Katie and I am a 20-something year old living in the beautiful city of Vancouver, BC. I am a recent graduate of the University of British Columbia with a Bachelor of Arts in Psychology and a minor in Sociology. I'}\n",
      "{'prompt': 'You killed my father', 'output': 'You killed my father, prepare to die.\\n\\nThe first time I saw this movie was in the theater. I was 12 years old and I was with my dad. I remember being so excited to see it. I had seen the trailer and I was'}\n",
      "{'prompt': 'My favourite colours are:', 'output': 'My favourite colours are:\\n\\n- Blue\\n- Green\\n- Purple\\n- Red\\n- Yellow\\n\\nI like blue because it is a calming colour. It is also the colour of the sky and the sea.\\n\\nI like green because it is'}\n",
      "{'prompt': 'What is the airspeed of an unladen', 'output': 'What is the airspeed of an unladen swallow?\\n\\nThe answer to this question is 11 m/s, or 24.2 mph.\\n\\nThe question is from the Monty Python sketch “The Philosophers’ Football Match”.\\n\\nThe sketch is'}\n",
      "[{'output': 'Hello, my name is Katie and I am a 20-something year old living '\n",
      "            'in the beautiful city of Vancouver, BC. I am a recent graduate of '\n",
      "            'the University of British Columbia with a Bachelor of Arts in '\n",
      "            'Psychology and a minor in Sociology. I',\n",
      "  'prompt': 'Hello, my name is'},\n",
      " {'output': 'You killed my father, prepare to die.\\n'\n",
      "            '\\n'\n",
      "            'The first time I saw this movie was in the theater. I was 12 '\n",
      "            'years old and I was with my dad. I remember being so excited to '\n",
      "            'see it. I had seen the trailer and I was',\n",
      "  'prompt': 'You killed my father'},\n",
      " {'output': 'My favourite colours are:\\n'\n",
      "            '\\n'\n",
      "            '- Blue\\n'\n",
      "            '- Green\\n'\n",
      "            '- Purple\\n'\n",
      "            '- Red\\n'\n",
      "            '- Yellow\\n'\n",
      "            '\\n'\n",
      "            'I like blue because it is a calming colour. It is also the colour '\n",
      "            'of the sky and the sea.\\n'\n",
      "            '\\n'\n",
      "            'I like green because it is',\n",
      "  'prompt': 'My favourite colours are:'},\n",
      " {'output': 'What is the airspeed of an unladen swallow?\\n'\n",
      "            '\\n'\n",
      "            'The answer to this question is 11 m/s, or 24.2 mph.\\n'\n",
      "            '\\n'\n",
      "            'The question is from the Monty Python sketch “The Philosophers’ '\n",
      "            'Football Match”.\\n'\n",
      "            '\\n'\n",
      "            'The sketch is',\n",
      "  'prompt': 'What is the airspeed of an unladen'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "result = futuremap.result()\n",
    "for row in result:\n",
    "    print(row)\n",
    "pprint(result)\n",
    "# https://distributed.dask.org/en/stable/quickstart.html#gather need to use gather instead\n",
    "#outputs = client.gather(iter(futuremap))\n",
    "#print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3512bb8d-9b75-4163-a59b-9ca412df228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Stopping worker: SLURMCluster-0 job: 2537\n",
      "DEBUG:Executing the following command to command line\n",
      "scancel 2537\n",
      "DEBUG:Closed job 2537\n",
      "DEBUG:Executing the following command to command line\n",
      "scancel 2537\n",
      "DEBUG:Closed job 2537\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
